{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.04798871, 0.098203465]\n",
      "2 [0.08511786, 0.17403208]\n",
      "4 [0.09488814, 0.1938118]\n",
      "6 [0.09750616, 0.19894828]\n",
      "8 [0.09825188, 0.2002603]\n",
      "10 [0.09850511, 0.20057462]\n",
      "12 [0.09862654, 0.20062979]\n",
      "14 [0.0987106, 0.20061867]\n",
      "16 [0.0987821, 0.20059158]\n",
      "18 [0.09884769, 0.20056161]\n",
      "20 [0.09890923, 0.20053211]\n",
      "22 [0.09896735, 0.20050389]\n",
      "24 [0.099022344, 0.2004771]\n",
      "26 [0.09907439, 0.2004517]\n",
      "28 [0.09912367, 0.20042765]\n",
      "30 [0.09917033, 0.20040488]\n",
      "32 [0.0992145, 0.20038334]\n",
      "34 [0.09925632, 0.20036292]\n",
      "36 [0.099295914, 0.2003436]\n",
      "38 [0.0993334, 0.20032531]\n",
      "40 [0.099368885, 0.200308]\n",
      "42 [0.09940248, 0.20029159]\n",
      "44 [0.099434294, 0.20027606]\n",
      "46 [0.09946442, 0.20026137]\n",
      "48 [0.09949293, 0.20024745]\n",
      "50 [0.09951993, 0.20023428]\n",
      "52 [0.09954549, 0.2002218]\n",
      "54 [0.09956969, 0.20020999]\n",
      "56 [0.0995926, 0.20019881]\n",
      "58 [0.099614285, 0.20018823]\n",
      "60 [0.09963482, 0.2001782]\n",
      "62 [0.099654265, 0.20016871]\n",
      "64 [0.09967267, 0.20015974]\n",
      "66 [0.09969009, 0.20015123]\n",
      "68 [0.09970659, 0.20014319]\n",
      "70 [0.099722214, 0.20013557]\n",
      "72 [0.099737, 0.20012835]\n",
      "74 [0.099751, 0.20012152]\n",
      "76 [0.09976426, 0.20011505]\n",
      "78 [0.09977681, 0.20010892]\n",
      "80 [0.099788696, 0.20010312]\n",
      "82 [0.099799946, 0.20009762]\n",
      "84 [0.0998106, 0.20009242]\n",
      "86 [0.09982069, 0.2000875]\n",
      "88 [0.09983023, 0.20008285]\n",
      "90 [0.09983927, 0.20007844]\n",
      "92 [0.09984782, 0.20007427]\n",
      "94 [0.09985592, 0.2000703]\n",
      "96 [0.099863596, 0.20006657]\n",
      "98 [0.09987086, 0.20006302]\n",
      "100 [0.09987774, 0.20005967]\n",
      "102 [0.09988425, 0.2000565]\n",
      "104 [0.09989041, 0.20005348]\n",
      "106 [0.099896245, 0.20005064]\n",
      "108 [0.09990177, 0.20004794]\n",
      "110 [0.099907, 0.20004538]\n",
      "112 [0.09991196, 0.20004296]\n",
      "114 [0.099916644, 0.20004067]\n",
      "116 [0.099921085, 0.20003851]\n",
      "118 [0.09992529, 0.20003645]\n",
      "120 [0.099929266, 0.20003451]\n",
      "122 [0.09993303, 0.20003268]\n",
      "124 [0.0999366, 0.20003094]\n",
      "126 [0.09993997, 0.2000293]\n",
      "128 [0.09994316, 0.20002773]\n",
      "130 [0.099946186, 0.20002626]\n",
      "132 [0.09994905, 0.20002487]\n",
      "134 [0.09995175, 0.20002355]\n",
      "136 [0.09995432, 0.2000223]\n",
      "138 [0.09995675, 0.20002112]\n",
      "140 [0.099959046, 0.20001999]\n",
      "142 [0.09996122, 0.20001893]\n",
      "144 [0.099963285, 0.20001791]\n",
      "146 [0.09996524, 0.20001696]\n",
      "148 [0.09996709, 0.20001605]\n",
      "150 [0.09996884, 0.2000152]\n",
      "152 [0.099970505, 0.2000144]\n",
      "154 [0.09997208, 0.20001364]\n",
      "156 [0.09997356, 0.2000129]\n",
      "158 [0.09997497, 0.20001222]\n",
      "160 [0.0999763, 0.20001157]\n",
      "162 [0.09997756, 0.20001096]\n",
      "164 [0.09997875, 0.20001037]\n",
      "166 [0.099979885, 0.20000982]\n",
      "168 [0.09998096, 0.2000093]\n",
      "170 [0.09998197, 0.2000088]\n",
      "172 [0.09998293, 0.20000833]\n",
      "174 [0.09998384, 0.20000789]\n",
      "176 [0.099984705, 0.20000747]\n",
      "178 [0.09998552, 0.20000707]\n",
      "180 [0.09998629, 0.2000067]\n",
      "182 [0.09998702, 0.20000634]\n",
      "184 [0.099987715, 0.200006]\n",
      "186 [0.09998837, 0.20000567]\n",
      "188 [0.09998899, 0.20000537]\n",
      "190 [0.09998958, 0.20000508]\n",
      "192 [0.09999014, 0.20000482]\n",
      "194 [0.099990666, 0.20000456]\n",
      "196 [0.099991165, 0.20000432]\n",
      "198 [0.099991634, 0.20000409]\n",
      "200 [0.099992074, 0.20000388]\n"
     ]
    }
   ],
   "source": [
    "#使用numpy生成100随机点\n",
    "x_data = np.random.rand(100)\n",
    "y_data = x_data*0.1+0.2\n",
    "\n",
    "#构造一个线性模型\n",
    "b = tf.Variable(0.)\n",
    "k = tf.Variable(0.)\n",
    "y = k*x_data + b\n",
    "\n",
    "#二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y_data-y))\n",
    "#定义一个梯度下降法来进行训练的优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.2)\n",
    "#最小化代价函数\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(201):\n",
    "        sess.run(train)\n",
    "        if step%2==0:\n",
    "            print(step,sess.run([k,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
